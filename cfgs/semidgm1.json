{
    "config name" : "semidgm",

    "dataset" : "mnist",
    "dataset params" : {
        "semi-supervised" : true,               //
        "output_shape" : [28, 28, 1],            //
        "nb_labelled_images_per_class" : 100    //
    },

    // the validator output, tensorboard output and tensorflow checkpoint will be
    // saved under this directory
    "assets dir" : "assets/semidgm/semidgm4",

    // "semi-supervised learning with deep generative models"
    // implemention is in models/semi_dgm2.py
    "model" : "semidgm",
    "model params" : {
        "name" : "semidgm",

        // shape params config
        "input_shape" : [28, 28, 1],
        "nb_classes" : 10,
        "hz_dim" : 20,
        "hx_dim" : 50,

        // optimizers config
        // other optimizers are in utils/optimizer.py
        "m1 optimizer" : "rmsprop",
        "m1 optimizer params" : {
            "lr" : 0.001,
            "lr scheme" : "exponential",
            "lr params" : {
                "decay_steps" : 2000,
                "decay_rate" : 0.8
            }
        },


        "m2 optimizer" : "rmsprop",
        "m2 optimizer params" : {
            "lr" : 0.001,
            "lr scheme" : "exponential",
            "lr params" : {
                "decay_steps" : 2000,
                "decay_rate" : 0.8
            }
        },

        // learning rate scheme
        // other learning rate schemes are in utils/learning_rate.py

        "m1 train steps" : 4000,

        "summary" : true,
        "debug" : true,

        // the weight of different losses
        // default loss weight is 1.0
        "m1 loss weights" : {
            "kl z loss weight" : 0.001,
            "reconstruction loss weight" : 1.0
        },
        "m2 loss weights" : {
            "kl z loss weight" : 0.0001,
            "kl y loss weight" : 1,
            "reconstruction loss weight" : 0.1,
            "classification loss weight" : 1.0,
            "regularization loss weight" : 0.0060,

            "supervised loss weight" : 1.0,
            "unsupervised loss weight" : 0.04
        },

        // network define
        //
        // x -(encoder)-> hx -(decoder)-> x
        //                hx -(classifier)-> y
        //                [hx, y] -(encoder)-> hz 
        //                                    [hz, y] -(decoder)-> hx
        "x encoder" : "EncoderSimple",
        "x encoder params" : {
            "nb_conv_blocks" : 0,
            "batch_norm" : "none",
            "nb_fc_nodes" : [600, 600],
            "output_distribution": "gaussian"
        },

        "hx decoder" : "DecoderSimple",
        "hx decoder params" : {
            "batch_norm" : "none",
            "nb_fc_nodes" : [600, 600],
            "including_deconv" : false,
            "fc_output_reshape" : [28, 28, 1],
            "output_activation" : "sigmoid"
        },

        "hx y encoder" : "EncoderSimple",
        "hx y encoder params" : {
            "nb_conv_blocks" : 0,
            "batch_norm" : "none",
            "nb_fc_nodes" : [40, 40],
            "output_distribution": "gaussian"
        },

        "hz y decoder" : "DecoderSimple",
        "hz y decoder params" : {
            "nb_deconv_blocks" : 0,
            "batch_norm" : "none",
            "nb_fc_nodes" : [40, 40],
            "including_deconv" : false,
            "output_activation" : "sigmoid"
        },

        "hx classifier" : "ClassifierSimple",
        "hx classifier params" : {
            "nb_conv_blocks" : 0,
            "batch_norm" : "none",
            "nb_fc_nodes" : [30],
            "output_activation" : "none"
        }
    },


    "trainer" : "semi-supervised",
    "trainer params" : {

        // "continue train" : true,
        // "load checkpoint assets dir" : "assets/semidgm/semidgm_m1", // load checkpoint from other assets dir

        "summary dir" : "log",
        "summary hyperparams string" : "unsupervised_loss_weight_0_04",

        "summary steps" : 100,                  //save tensorboard summary interval steps (default 0 is not to save)
        // "save checkpoint steps" : 5000,         //save checkpoint interval steps (default 0 is not to save)
        "log steps" : 100,                      //print log interval steps (default 0 is not to print)

        "train steps" : 20000,                  //maximum total train steps

        "pretrain steps" : [
            ["unsupervised", 4000]
            ,
            ["supervised", 3000]
        ], 

        "supervised step" : 1,
        "unsupervised step" : 5,

        "batch_size" : 128,
        "debug" : true,

        "validators" : [
            {
                "validator" : "dataset_validator",
                "validate steps" : 500,
                "has summary" : true,
                // "continue train" : true, // prevent overwrite previous result file
                "validator params" : {
                    "metric" : "accuracy",
                    "metric type" : "top1"
                }
            }
            // ,
            // {
            //     "validator" : "scatter_plot_validator",
            //     "validate steps" : 5000,
            //     "validator params" : {
            //         "watch variable" : "hidden dist",
            //         "x dim" : 0,
            //         "y dim" : 1,
            //         "log dir" : "scatter1"
            //     }
            // }
        ]
    
    }
}


